{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Xuan Jiang\n",
    "- Mingjun Sun\n",
    "- Yu Xu\n",
    "- Jieru Lin\n",
    "- Zijie Feng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "\n",
    "The present study aims to develop a predictive model for customer attrition in credit card services, which could be critical for banks enhancing customer retention. Leveraging a dataset of 10127 observations with 23 variables, including demographic and transactional information, this study proposes an integrated approach that combines supervised and unsupervised algorithms. The variables are measured using different scales and formats, such as categorical variables and numerical variables measured by monetary units. The data will be preprocessed to handle missing values, scale numerical features, and encode categorical variables. Dimensionality reduction techniques, such as Principal Component Analysis (PCA), will also be applied to further simplify the dataset and improve computational efficiency. Subsequently, clustering algorithms, such as K-means, Gaussian Mixture Model (GMM), and DBSCAN will be used to identify distinct customer segments prone to attrition, providing banks valuable insights for targeted retention rate. Performance evaluation will be conducted using metrics such as Rand Index and F1 Score, comparing predictions against true labels. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In the United States, credit cards are among the most widely used consumer financial instruments; as of 2019, over 75% of households had at least one general-purpose credit card<a name=\"adams\"></a>[<sup>[1]</sup>](#adamsnote). Credit cards are not only important to people’s daily usage, but also an important part of bank profit. Customers have many alternatives and may evaluate multiple banks based on their prior experiences of being treated, therefore competition between banks is quite severe because products are somewhat identical<a name=\"miao\"></a>[<sup>[2]</sup>](#miaonote). Banks need to pay attention to their customers and try to avoid customer loss. It has been improved that retaining an existing customer costs much less than acquiring a new one<a name=\"ahmad\"></a>[<sup>[3]</sup>](#ahmadnote). This means that predicting customer attrition is quite important because banks can adjust credit services based on the factors that influence customer attrition and increase retention rates.\n",
    "\n",
    "Previous research has employed supervised machine learning algorithms including Random Forest, KNN, and Linear Regression to predict characteristics that influence customer attrition. According to Xinyu Miao and Haoran Wang's paper, Customer Churn Prediction on Credit Card Services using Random Forest Method, the total transaction amount in the last 12 months, total transaction count in the last 12 months, and total credit card revolving balance all have a significant impact on customer attrition forecasting. However, the article relied on a single model to generate predictions, which may be limiting. As a result, in our study, we will employ supervised machine learning approaches to identify factors influencing customer attrition and compare our findings to past research.\n",
    "\n",
    "Another paper aimed to develop customer churn prediction models using two-step clusterings to improve the categorical independent variables. The categorical variables included gender, education level, marital status, income category, and product variable, which were forwarded to the two-step clustering model to merge the variables into one categorical variable that described all the categorical variables in the dataset<a name=\"dana\"></a>[<sup>[4]</sup>](#dananote). This not only inspired us how to narrow down the categorical variables but also encouraged us to use clustering algorithms such as K-Means, GMM, and DBSCAN to categorize customers when there are mixed types of variables in the datasets.  \n",
    "\n",
    "Our research aims to merge these two perspectives, considering the significant factors as well as the clustering algorithm, to provide a new understanding of customer segmentation in credit card services for banks to understand what kind of customers tend to end up with attrition.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The primary mission of this study is to build an efficient model to successfully predict whether credit card customers will end up with attrition, by examining information like customer education level, income level, revolving balance, and more. \n",
    "\n",
    "However, with 20 ordinal, nominal, and numerical features, the computational expenses required to train most machine learning models can be overwhelming, making the resulting model complex and hard to interpret. This indicates the necessity of using some dimensionality reduction mechanism to simplify the data before training and predicting. Such operations can reduce computational complexity and make it easier when the model needs to be further tuned. \n",
    "\n",
    "After the data has been simplified by the dimensionality reduction process, comes the step of selecting some sort of model to make the predictions about each customer, using this data. The resulting predictions will only contain 2 unique values of attrition or no attrition so we can compare the predictions against the original true labels to understand the performance of the model and perhaps go back and change some things to see if performance improves.\n",
    "\n",
    "In summary, this problem involves dimensionality reduction of the data and model selection to enable accurate prediction of customer attrition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Link to the dataset: https://www.kaggle.com/datasets/thedevastator/predicting-credit-card-customer-attrition-with-m/data. \n",
    "\n",
    "Size of the dataset: \n",
    "- Number of variables: 23\n",
    "- Number of observations: 10127 \n",
    "\n",
    "The dataset contains demographic information such as age, gender, marital status, and education level. The datasets also consist of variables such as the Income category of the customer, Type of card held by the customer, Number of months the customer has been inactive in the last twelve months, Total revolving balance of the customer, Credit limit of customer, Total transaction amount, Total amount changed from quarter 4 to quarter 1, Total transaction count,  which are closely related to predicting customer attrition. \n",
    "\n",
    "There are observations whose “Education levels”, “Marital status”, and “Income category” are “Unknown”, therefore, during the data cleaning, we need to consider whether to keep these observations or not. Since the total number of observations is 10127, after data cleaning, we need to keep track of the total number of useful observations to ensure the dataset is large enough.  \n",
    "\n",
    "The last two columns' names are too long: “Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1” and “Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2”, during the data cleaning, we need to rename the columns. \n",
    "\n",
    "We realized that the last column is “Attrition Flag”, therefore we will drop this column during data cleaning. \n",
    "\n",
    "Since 23 variables are potentially related to customer attrition, we need to narrow these variables down to make the process of training models more straightforward. Therefore, during the EDA, we will create data visualizations that present some distinguished variables that are related to customer attrition to decide what variables should be used for data training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "First, the dataset should be preprocessed with a standard scaler, one hot encoder, and an ordinal encoder so it is easier to work with. Then we can use PCA as our dimensionality reduction processor to reduce data complexity. Within this process, we need to determine the optimal amount of PCA components so that our data can be fairly simple but still retain enough information from the original dataset. Graphs can be made for feature importance illustration if we determine the number of PCA components to be 1, 2, or 3. With our simplified data from PCA, we can now choose a clustering mechanism to make 2 clusters with one indicating attrition and the other indicating no attrition. In terms of the choices of clustering mechanisms, we can compare the performances between several algorithms including K-means, GMM, and DBSCAN. When measuring the performances, we should be able to deploy metrics such as the rand index and the f1 score using predictions from the models and the true labels from the original dataset. \n",
    "\n",
    "In terms of the specific library and functions that we are going to use, scikit-learn should have us covered for the standard scaler, one hot encoder, ordinal encoder, PCA, K-means, GMM, DBSCAN, rand score, and f1 score. Of course, we would also need numpy and pandas for basic data preparation. And, matplotlib and seaborn would be needed for EDA and interpretation of our algorithms.\n",
    "    \n",
    "In terms of having a benchmark model, the publisher of the dataset puts in a column of predictions made by a Naive Bayes Classifier which can be compared with the results from our models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "External validation metrics:\n",
    "\n",
    "- The Rand Index(RI) calculates the similarity between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings. The Rand score, ranging from 0 to 1, is the number of agreeing pairs divided by the total number of pairs. Higher rand scores indicate higher similarity. The adjusted rand score is calculated with the equation: ARI = (RI - Expected_RI) / (max(RI) - Expected_RI). It is ensured to have a value close to 0.0 for random labeling independently of the number of clusters and samples and exactly 1.0 for identical clustering, which is a more accurate measure.\n",
    "\n",
    "- F1 Score: While typically used in classification, the F1 score can be adapted for clustering by considering one cluster as the positive class (e.g., attrition) and the other as the negative class (e.g., existing customer). This requires assigning cluster labels based on the dominant class in each cluster and then calculating precision and recall to get the F1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we adhere to ethical guidelines and privacy considerations in line with established data science ethic checklist https://deon.drivendata.org/#data-science-ethics-checklist. Nevertheless, we have ensured to acknowledge the original data source in our report's footnotes, given its public availability.\n",
    "\n",
    "The dataset we employed encompasses extensive demographic information, including age, gender, marital status, and income category. It also provides insights into the customers' interactions with their credit card provider and their spending habits. Throughout our analysis, we should be conscious to avoid bias over the data patterns we see and to honestly represent our data, ensuring that our visualizations, summary statistics, and documentation reflect the data accurately and transparently.\n",
    "\n",
    "In selecting models for our analysis, we considered a variety of algorithms, including K-means, GMM (Gaussian Mixture Models), and DBSCAN (Density-Based Spatial Clustering of Applications with Noise), alongside metrics such as the Rand index and the F1 score. This approach ensures a balanced evaluation of model performance and supports our justification for selecting the most appropriate modeling techniques.\n",
    "\n",
    "As we present our results, it is paramount that our reporting does not inadvertently single out any specific groups or individuals. Our focus remains squarely on the predictive powers of the variables under consideration in relation to attrition decisions, ensuring our findings contribute meaningfully to understanding customer dynamics without compromising ethical standards or privacy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Team Expectation 1*: Be available to attend weekly meetings on Tuesday. Notice the rest of the group beforehand if unavailable for a meeting and is responsible for reaching out to get caught up and see what contributions you can make.\n",
    "- *Team Expectation 2*: Make sure to notice other group members once you update your work to the shared repo. Give timely feedback on group members' work to ensure all peers are supported and everyone is on the same page.\n",
    "- *Team Expectation 3*: Volunteer and contribute where you can, especially when another team member needs help or an opinion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/13  |  5 PM |  Brainstorm topics/questions (all)  |Discuss and decide on final project topic; discuss hypothesis; search for relevant datasets(all); begin background research(Jieru), Hypothesis and solution(Zijie), ethics(Yu), abstract (Mingjun), and evaluation matrix(Xuan); draft project proposal | \n",
    "| 2/19  |  1 PM |  Project proposal drafted | Edit, finalize, and submit proposal (all) | \n",
    "| 2/25  |  1 PM |  Review graded project proposal   | Update project proposal; Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 3/3  | 6 PM  | Import & Wrangle Data, do some EDA ( Xuan, Yu) | Review/Edit wrangling/EDA (Yu, Jieru); Discuss Analysis Plan (all)  |\n",
    "| 3/10  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Zijie, Mingjun) | Discuss/edit project code; Complete project (all) |\n",
    "| 3/14  | 12 PM  | Complete analysis (Xuan; Draft results/conclusion/discussion (all)| Discuss/edit full project(all) |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"adamsnote\"></a>1.[^](#adams)Adams, R., Bord, V. M., & Katcher, B. (2022, September 9). Credit Card Profitability. https://www.federalreserve.gov/econres/notes/feds-notes/credit-card-profitability-20220909.html. <br>\n",
    "<a name=\"miaonote\"></a>2.[^](#miao)Miao, X., & Wang, H. (2022). Customer Churn Prediction on Credit Card Services using Random Forest Method. Atlantis Press. https://www.atlantis-press.com/proceedings/icfied-22/125971597.<br>\n",
    "<a name=\"ahmadnote\"></a>3.[^](#ahmad)Ahmad, A. K., Jafar, A., & Aljoumaa, K. (2019). Customer Churn Prediction in Telecom Using Machine Learning in Big Data Platform. Journal of Big Data, 6(28). https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0191-6. <br>\n",
    "<a name=\"dananote\"></a>4.[^](#dana)Dana AL-Najjar, Nadia Al-Rousan, and Hazem Al-Najjar (2020, Machine Learning to Develop Credit Card Customer Churn Prediction. Artificial Intelligence Applications in Financial Technology). https://www.mdpi.com/0718-1876/17/4/77."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
